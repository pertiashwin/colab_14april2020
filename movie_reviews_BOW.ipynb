{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['films', 'adapted', 'from', 'comic', 'books', 'have', ...]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews \n",
    "\n",
    "pos_reviews = []\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    words = movie_reviews.words(fileid)\n",
    "    pos_reviews.append(words)\n",
    "\n",
    "neg_reviews = []\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    words = movie_reviews.words(fileid)\n",
    "    neg_reviews.append(words)\n",
    "\n",
    "# print first positive review item from the pos_reviews list\n",
    "print (pos_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot\n"
     ]
    }
   ],
   "source": [
    "print(neg_reviews[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_reviews) # 1000\n",
    "len(neg_reviews[0]) #879\n",
    "len(neg_reviews[0][0]) # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success', ',', 'whether', 'they', \"'\", 're', 'about', 'superheroes', '(', 'batman', ',']\n"
     ]
    }
   ],
   "source": [
    "# print first 20 items of the first item of positive review\n",
    "print(pos_reviews[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an']\n"
     ]
    }
   ],
   "source": [
    "print(neg_reviews[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': True, 'bad': True}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import string \n",
    "\n",
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "# feature extractor function\n",
    "def bag_of_words(words):\n",
    "    words_clean = []\n",
    "\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords_english and word not in string.punctuation:\n",
    "            words_clean.append(word)\n",
    "    words_dictionary = dict([word, True] for word in words_clean)\n",
    "    return words_dictionary\n",
    "\n",
    "# using dict will remove duplicate words from the words list\n",
    "# note the output: stopword 'the' is also removed\n",
    "print (bag_of_words(['the', 'the', 'good', 'bad', 'the', 'good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'films': True, 'adapted': True, 'comic': True, 'books': True, 'plenty': True, 'success': True, 'whether': True, 'superheroes': True, 'batman': True, 'superman': True, 'spawn': True, 'geared': True, 'toward': True, 'kids': True, 'casper': True, 'arthouse': True, 'crowd': True, 'ghost': True, 'world': True, 'never': True, 'really': True, 'book': True, 'like': True, 'hell': True, 'starters': True, 'created': True, 'alan': True, 'moore': True, 'eddie': True, 'campbell': True, 'brought': True, 'medium': True, 'whole': True, 'new': True, 'level': True, 'mid': True, '80s': True, '12': True, 'part': True, 'series': True, 'called': True, 'watchmen': True, 'say': True, 'thoroughly': True, 'researched': True, 'subject': True, 'jack': True, 'ripper': True, 'would': True, 'saying': True, 'michael': True, 'jackson': True, 'starting': True, 'look': True, 'little': True, 'odd': True, 'graphic': True, 'novel': True, '500': True, 'pages': True, 'long': True, 'includes': True, 'nearly': True, '30': True, 'consist': True, 'nothing': True, 'footnotes': True, 'words': True, 'dismiss': True, 'film': True, 'source': True, 'get': True, 'past': True, 'thing': True, 'might': True, 'find': True, 'another': True, 'stumbling': True, 'block': True, 'directors': True, 'albert': True, 'allen': True, 'hughes': True, 'getting': True, 'brothers': True, 'direct': True, 'seems': True, 'almost': True, 'ludicrous': True, 'casting': True, 'carrot': True, 'top': True, 'well': True, 'anything': True, 'riddle': True, 'better': True, 'set': True, 'ghetto': True, 'features': True, 'violent': True, 'street': True, 'crime': True, 'mad': True, 'geniuses': True, 'behind': True, 'menace': True, 'ii': True, 'society': True, 'question': True, 'course': True, 'whitechapel': True, '1888': True, 'london': True, 'east': True, 'end': True, 'filthy': True, 'sooty': True, 'place': True, 'whores': True, 'unfortunates': True, 'nervous': True, 'mysterious': True, 'psychopath': True, 'carving': True, 'profession': True, 'surgical': True, 'precision': True, 'first': True, 'stiff': True, 'turns': True, 'copper': True, 'peter': True, 'godley': True, 'robbie': True, 'coltrane': True, 'enough': True, 'calls': True, 'inspector': True, 'frederick': True, 'abberline': True, 'johnny': True, 'depp': True, 'blow': True, 'crack': True, 'case': True, 'widower': True, 'prophetic': True, 'dreams': True, 'unsuccessfully': True, 'tries': True, 'quell': True, 'copious': True, 'amounts': True, 'absinthe': True, 'opium': True, 'upon': True, 'arriving': True, 'befriends': True, 'unfortunate': True, 'named': True, 'mary': True, 'kelly': True, 'heather': True, 'graham': True, 'proceeds': True, 'investigate': True, 'horribly': True, 'gruesome': True, 'crimes': True, 'even': True, 'police': True, 'surgeon': True, 'stomach': True, 'think': True, 'anyone': True, 'needs': True, 'briefed': True, 'go': True, 'particulars': True, 'unique': True, 'interesting': True, 'theory': True, 'identity': True, 'killer': True, 'reasons': True, 'chooses': True, 'slay': True, 'bother': True, 'cloaking': True, 'screenwriters': True, 'terry': True, 'hayes': True, 'vertical': True, 'limit': True, 'rafael': True, 'yglesias': True, 'les': True, 'mis': True, 'rables': True, 'good': True, 'job': True, 'keeping': True, 'hidden': True, 'viewers': True, 'funny': True, 'watch': True, 'locals': True, 'blindly': True, 'point': True, 'finger': True, 'blame': True, 'jews': True, 'indians': True, 'englishman': True, 'could': True, 'capable': True, 'committing': True, 'ghastly': True, 'acts': True, 'ending': True, 'whistling': True, 'stonecutters': True, 'song': True, 'simpsons': True, 'days': True, 'holds': True, 'back': True, 'electric': True, 'car': True, 'made': True, 'steve': True, 'guttenberg': True, 'star': True, 'worry': True, 'make': True, 'sense': True, 'see': True, 'onto': True, 'appearance': True, 'certainly': True, 'dark': True, 'bleak': True, 'surprising': True, 'much': True, 'looks': True, 'tim': True, 'burton': True, 'planet': True, 'apes': True, 'times': True, 'sleepy': True, 'hollow': True, '2': True, 'print': True, 'saw': True, 'completely': True, 'finished': True, 'color': True, 'music': True, 'finalized': True, 'comments': True, 'marilyn': True, 'manson': True, 'cinematographer': True, 'deming': True, 'word': True, 'ably': True, 'captures': True, 'dreariness': True, 'victorian': True, 'era': True, 'helped': True, 'flashy': True, 'killing': True, 'scenes': True, 'remind': True, 'crazy': True, 'flashbacks': True, 'twin': True, 'peaks': True, 'though': True, 'violence': True, 'pales': True, 'comparison': True, 'black': True, 'white': True, 'oscar': True, 'winner': True, 'martin': True, 'childs': True, 'shakespeare': True, 'love': True, 'production': True, 'design': True, 'original': True, 'prague': True, 'surroundings': True, 'one': True, 'creepy': True, 'acting': True, 'solid': True, 'dreamy': True, 'turning': True, 'typically': True, 'strong': True, 'performance': True, 'deftly': True, 'handling': True, 'british': True, 'accent': True, 'ians': True, 'holm': True, 'joe': True, 'gould': True, 'secret': True, 'richardson': True, '102': True, 'dalmatians': True, 'log': True, 'great': True, 'supporting': True, 'roles': True, 'big': True, 'surprise': True, 'cringed': True, 'time': True, 'opened': True, 'mouth': True, 'imagining': True, 'attempt': True, 'irish': True, 'actually': True, 'half': True, 'bad': True, 'however': True, '00': True, 'r': True, 'gore': True, 'sexuality': True, 'language': True, 'drug': True, 'content': True}, 'pos')\n"
     ]
    }
   ],
   "source": [
    "# positive reviews feature set\n",
    "pos_reviews_set = []\n",
    "for words in pos_reviews:\n",
    "    pos_reviews_set.append((bag_of_words(words), 'pos'))\n",
    "\n",
    "# negative reviews feature set\n",
    "neg_reviews_set = []\n",
    "for words in neg_reviews:\n",
    "    neg_reviews_set.append((bag_of_words(words), 'neg'))\n",
    "\n",
    "# print first positive review item from the pos_reviews list\n",
    "print (pos_reviews_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'plot': True, 'two': True, 'teen': True, 'couples': True, 'go': True, 'church': True, 'party': True, 'drink': True, 'drive': True, 'get': True, 'accident': True, 'one': True, 'guys': True, 'dies': True, 'girlfriend': True, 'continues': True, 'see': True, 'life': True, 'nightmares': True, 'deal': True, 'watch': True, 'movie': True, 'sorta': True, 'find': True, 'critique': True, 'mind': True, 'fuck': True, 'generation': True, 'touches': True, 'cool': True, 'idea': True, 'presents': True, 'bad': True, 'package': True, 'makes': True, 'review': True, 'even': True, 'harder': True, 'write': True, 'since': True, 'generally': True, 'applaud': True, 'films': True, 'attempt': True, 'break': True, 'mold': True, 'mess': True, 'head': True, 'lost': True, 'highway': True, 'memento': True, 'good': True, 'ways': True, 'making': True, 'types': True, 'folks': True, 'snag': True, 'correctly': True, 'seem': True, 'taken': True, 'pretty': True, 'neat': True, 'concept': True, 'executed': True, 'terribly': True, 'problems': True, 'well': True, 'main': True, 'problem': True, 'simply': True, 'jumbled': True, 'starts': True, 'normal': True, 'downshifts': True, 'fantasy': True, 'world': True, 'audience': True, 'member': True, 'going': True, 'dreams': True, 'characters': True, 'coming': True, 'back': True, 'dead': True, 'others': True, 'look': True, 'like': True, 'strange': True, 'apparitions': True, 'disappearances': True, 'looooot': True, 'chase': True, 'scenes': True, 'tons': True, 'weird': True, 'things': True, 'happen': True, 'explained': True, 'personally': True, 'trying': True, 'unravel': True, 'film': True, 'every': True, 'give': True, 'clue': True, 'kind': True, 'fed': True, 'biggest': True, 'obviously': True, 'got': True, 'big': True, 'secret': True, 'hide': True, 'seems': True, 'want': True, 'completely': True, 'final': True, 'five': True, 'minutes': True, 'make': True, 'entertaining': True, 'thrilling': True, 'engaging': True, 'meantime': True, 'really': True, 'sad': True, 'part': True, 'arrow': True, 'dig': True, 'flicks': True, 'actually': True, 'figured': True, 'half': True, 'way': True, 'point': True, 'strangeness': True, 'start': True, 'little': True, 'bit': True, 'sense': True, 'still': True, 'guess': True, 'bottom': True, 'line': True, 'movies': True, 'always': True, 'sure': True, 'given': True, 'password': True, 'enter': True, 'understanding': True, 'mean': True, 'showing': True, 'melissa': True, 'sagemiller': True, 'running': True, 'away': True, 'visions': True, '20': True, 'throughout': True, 'plain': True, 'lazy': True, 'okay': True, 'people': True, 'chasing': True, 'know': True, 'need': True, 'giving': True, 'us': True, 'different': True, 'offering': True, 'insight': True, 'apparently': True, 'studio': True, 'took': True, 'director': True, 'chopped': True, 'shows': True, 'might': True, 'decent': True, 'somewhere': True, 'suits': True, 'decided': True, 'turning': True, 'music': True, 'video': True, 'edge': True, 'would': True, 'actors': True, 'although': True, 'wes': True, 'bentley': True, 'seemed': True, 'playing': True, 'exact': True, 'character': True, 'american': True, 'beauty': True, 'new': True, 'neighborhood': True, 'kudos': True, 'holds': True, 'entire': True, 'feeling': True, 'unraveling': True, 'overall': True, 'stick': True, 'entertain': True, 'confusing': True, 'rarely': True, 'excites': True, 'feels': True, 'redundant': True, 'runtime': True, 'despite': True, 'ending': True, 'explanation': True, 'craziness': True, 'came': True, 'oh': True, 'horror': True, 'slasher': True, 'flick': True, 'packaged': True, 'someone': True, 'assuming': True, 'genre': True, 'hot': True, 'kids': True, 'also': True, 'wrapped': True, 'production': True, 'years': True, 'ago': True, 'sitting': True, 'shelves': True, 'ever': True, 'whatever': True, 'skip': True, 'joblo': True, 'nightmare': True, 'elm': True, 'street': True, '3': True, '7': True, '10': True, 'blair': True, 'witch': True, '2': True, 'crow': True, '9': True, 'salvation': True, '4': True, 'stir': True, 'echoes': True, '8': True}, 'neg')\n"
     ]
    }
   ],
   "source": [
    "print(neg_reviews_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_reviews_set))  # array contains words Feature list\n",
    "print(len(pos_reviews))   # array contains words list only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 1600\n"
     ]
    }
   ],
   "source": [
    "# radomize pos_reviews_set and neg_reviews_set\n",
    "# doing so will output different accuracy result everytime we run the program\n",
    "from random import shuffle \n",
    "shuffle(pos_reviews_set)\n",
    "shuffle(neg_reviews_set)\n",
    "\n",
    "test_set = pos_reviews_set[:200] + neg_reviews_set[:200]\n",
    "train_set = pos_reviews_set[200:] + neg_reviews_set[200:]\n",
    "\n",
    "print(len(test_set),  len(train_set)) # Output: (400, 1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Classifier and Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7025\n",
      "Most Informative Features\n",
      "               ludicrous = True              neg : pos    =     17.7 : 1.0\n",
      "                  sloppy = True              neg : pos    =     16.3 : 1.0\n",
      "               insulting = True              neg : pos    =     15.7 : 1.0\n",
      "                 sincere = True              pos : neg    =     12.3 : 1.0\n",
      "                  seagal = True              neg : pos    =     11.7 : 1.0\n",
      "                captures = True              pos : neg    =     11.4 : 1.0\n",
      "              astounding = True              pos : neg    =     11.0 : 1.0\n",
      "                    slip = True              pos : neg    =     11.0 : 1.0\n",
      "               uplifting = True              pos : neg    =     11.0 : 1.0\n",
      "               laughably = True              neg : pos    =     10.3 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "print(accuracy) # Output: 0.7325\n",
    "\n",
    "print (classifier.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n",
      "<ProbDist with 2 samples>\n",
      "neg\n",
      "0.8411934459883227\n",
      "0.15880655401167806\n",
      "pos\n",
      "<ProbDist with 2 samples>\n",
      "pos\n",
      "0.059615519456250154\n",
      "0.9403844805437497\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "custom_review = \"I hated the film. It was a disaster. Poor direction, bad acting.\"\n",
    "custom_review_tokens = word_tokenize(custom_review)\n",
    "custom_review_set = bag_of_words(custom_review_tokens)\n",
    "print (classifier.classify(custom_review_set)) # Output: neg\n",
    "# Negative review correctly classified as negative\n",
    "\n",
    "# probability result\n",
    "prob_result = classifier.prob_classify(custom_review_set)\n",
    "print (prob_result) # Output: <ProbDist with 2 samples>\n",
    "print (prob_result.max()) # Output: neg\n",
    "print (prob_result.prob(\"neg\")) # Output: 0.776128854994\n",
    "print (prob_result.prob(\"pos\")) # Output: 0.223871145006\n",
    "\n",
    "custom_review = \"It was a wonderful and amazing movie. I loved it. Best direction, good acting.\"\n",
    "custom_review_tokens = word_tokenize(custom_review)\n",
    "custom_review_set = bag_of_words(custom_review_tokens)\n",
    "\n",
    "print (classifier.classify(custom_review_set)) # Output: pos\n",
    "# Positive review correctly classified as positive\n",
    "\n",
    "# probability result\n",
    "prob_result = classifier.prob_classify(custom_review_set)\n",
    "print (prob_result) # Output: <ProbDist with 2 samples>\n",
    "print (prob_result.max()) # Output: pos\n",
    "print (prob_result.prob(\"neg\")) # Output: 0.0972171562901\n",
    "print (prob_result.prob(\"pos\")) # Output: 0.90278284371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-gram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "\n",
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "# clean words, i.e. remove stopwords and punctuation\n",
    "def clean_words(words, stopwords_english):\n",
    "    words_clean = []\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords_english and word not in string.punctuation:\n",
    "            words_clean.append(word)\t\n",
    "    return words_clean \n",
    "# feature extractor function for unigram\n",
    "def bag_of_words(words):\t\n",
    "\twords_dictionary = dict([word, True] for word in words)\t\n",
    "\treturn words_dictionary\n",
    "\n",
    "# feature extractor function for ngrams (bigram)\n",
    "def bag_of_ngrams(words, n=2):\n",
    "\twords_ng = []\n",
    "\tfor item in iter(ngrams(words, n)):\n",
    "\t\twords_ng.append(item)\n",
    "\twords_dictionary = dict([word, True] for word in words_ng)\t\n",
    "\treturn words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'a', 'very', 'good', 'movie', '.']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "# feature extractor function for ngrams (bigram)\n",
    "# get 200 most frequently occurring bigrams from every review\n",
    "def bag_of_ngrams(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"It was a very good movie.\"\n",
    "words = word_tokenize(text.lower())\n",
    "\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'it': True, 'was': True, 'a': True, 'very': True, 'good': True, 'movie': True, '.': True, ('a', 'very'): True, ('good', 'movie'): True, ('it', 'was'): True, ('movie', '.'): True, ('very', 'good'): True, ('was', 'a'): True}\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_ngrams(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'movie']\n"
     ]
    }
   ],
   "source": [
    "words_clean = clean_words(words, stopwords_english)\n",
    "print (words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very', 'good', 'movie']\n"
     ]
    }
   ],
   "source": [
    "# cleaning words is find for unigrams\n",
    "# but this can omit important words for bigrams\n",
    "# for example, stopwords like very, over, under, so, etc. are important for bigrams\n",
    "# we create a new stopwords list specifically for bigrams by omitting such important words\n",
    "important_words = ['above', 'below', 'off', 'over', 'under', 'more', 'most', 'such', 'no', 'nor', 'not', 'only', 'so', 'than', 'too', 'very', 'just', 'but']\n",
    "\n",
    "stopwords_english_for_bigrams = set(stopwords_english) - set(important_words)\n",
    "\n",
    "words_clean_for_bigrams = clean_words(words, stopwords_english_for_bigrams)\n",
    "print (words_clean_for_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': True, 'movie': True}\n",
      "{'very': True, 'good': True, 'movie': True, ('good', 'movie'): True, ('very', 'good'): True}\n"
     ]
    }
   ],
   "source": [
    "unigram_features = bag_of_words(words_clean)\n",
    "print (unigram_features)\n",
    "\n",
    "bigram_features = bag_of_ngrams(words_clean_for_bigrams)\n",
    "print(bigram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': True, 'movie': True, 'very': True, ('good', 'movie'): True, ('very', 'good'): True}\n"
     ]
    }
   ],
   "source": [
    "# combine both unigram and bigram features\n",
    "all_features = unigram_features.copy()\n",
    "all_features.update(bigram_features)\n",
    "print (all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': True, 'movie': True, 'very': True, ('good', 'movie'): True, ('very', 'good'): True}\n"
     ]
    }
   ],
   "source": [
    "# let's define a new function that extracts all features\n",
    "# i.e. that extracts both unigram and bigrams features\n",
    "def bag_of_all_words(words, n=2):\n",
    "\twords_clean = clean_words(words, stopwords_english)\n",
    "\twords_clean_for_bigrams = clean_words(words, stopwords_english_for_bigrams)\n",
    "\n",
    "\tunigram_features = bag_of_words(words_clean)\n",
    "\tbigram_features = bag_of_ngrams(words_clean_for_bigrams)\n",
    "\n",
    "\tall_features = unigram_features.copy()\n",
    "\tall_features.update(bigram_features)\n",
    "\n",
    "\treturn all_features\n",
    "\n",
    "print (bag_of_all_words(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews \n",
    "\n",
    "pos_reviews = []\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    words = movie_reviews.words(fileid)\n",
    "    pos_reviews.append(words)\n",
    "\n",
    "neg_reviews = []\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    words = movie_reviews.words(fileid)\n",
    "    neg_reviews.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive reviews feature set\n",
    "pos_reviews_set = []\n",
    "for words in pos_reviews:\n",
    "\tpos_reviews_set.append((bag_of_all_words(words), 'pos'))\n",
    "\n",
    "# negative reviews feature set\n",
    "neg_reviews_set = []\n",
    "for words in neg_reviews:\n",
    "\tneg_reviews_set.append((bag_of_all_words(words), 'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n",
      "400 1600\n"
     ]
    }
   ],
   "source": [
    "print (len(pos_reviews_set), len(neg_reviews_set)) # Output: (1000, 1000)\n",
    "\n",
    "# radomize pos_reviews_set and neg_reviews_set\n",
    "# doing so will output different accuracy result everytime we run the program\n",
    "from random import shuffle \n",
    "shuffle(pos_reviews_set)\n",
    "shuffle(neg_reviews_set)\n",
    "\n",
    "test_set = pos_reviews_set[:200] + neg_reviews_set[:200]\n",
    "train_set = pos_reviews_set[200:] + neg_reviews_set[200:]\n",
    "\n",
    "print(len(test_set),  len(train_set)) # Output: (400, 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     19.4 : 1.0\n",
      "                   sucks = True              neg : pos    =     14.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     14.2 : 1.0\n",
      "               stupidity = True              neg : pos    =     11.8 : 1.0\n",
      "              astounding = True              pos : neg    =     11.0 : 1.0\n",
      "               affecting = True              pos : neg    =     11.0 : 1.0\n",
      "                   fares = True              neg : pos    =     10.3 : 1.0\n",
      "                  finest = True              pos : neg    =     10.1 : 1.0\n",
      "      ('change', 'pace') = True              pos : neg    =      9.7 : 1.0\n",
      "      ('pop', 'culture') = True              pos : neg    =      9.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "print(accuracy) # Output: 0.8025\n",
    "\n",
    "print (classifier.show_most_informative_features(10))\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy has increased to 80% while using combined (unigram + bigram) features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Classifier and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n",
      "<ProbDist with 2 samples>\n",
      "neg\n",
      "0.9655671232377713\n",
      "0.034432876762229024\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "custom_review = \"I hated the film. It was a disaster. Poor direction, bad acting.\"\n",
    "custom_review_tokens = word_tokenize(custom_review)\n",
    "custom_review_set = bag_of_all_words(custom_review_tokens)\n",
    "print (classifier.classify(custom_review_set)) # Output: neg\n",
    "# Negative review correctly classified as negative\n",
    "\n",
    "# probability result\n",
    "prob_result = classifier.prob_classify(custom_review_set)\n",
    "print (prob_result) # Output: <ProbDist with 2 samples>\n",
    "print (prob_result.max()) # Output: neg\n",
    "print (prob_result.prob(\"neg\")) # Output: 0.770612685688\n",
    "print (prob_result.prob(\"pos\")) # Output: 0.229387314312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "<ProbDist with 2 samples>\n",
      "pos\n",
      "0.029131382448065773\n",
      "0.9708686175519347\n"
     ]
    }
   ],
   "source": [
    "custom_review = \"It was a wonderful and amazing movie. I loved it. Best direction, good acting.\"\n",
    "custom_review_tokens = word_tokenize(custom_review)\n",
    "custom_review_set = bag_of_all_words(custom_review_tokens)\n",
    "\n",
    "print (classifier.classify(custom_review_set)) # Output: pos\n",
    "# Positive review correctly classified as positive\n",
    "\n",
    "# probability result\n",
    "prob_result = classifier.prob_classify(custom_review_set)\n",
    "print (prob_result) # Output: <ProbDist with 2 samples>\n",
    "print (prob_result.max()) # Output: pos\n",
    "print (prob_result.prob(\"neg\")) # Output: 0.00677736186354\n",
    "print (prob_result.prob(\"pos\")) # Output: 0.993222638136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
